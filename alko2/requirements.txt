torch>=2.3
transformers>=4.43
datasets>=2.19
accelerate>=0.33
deepspeed>=0.14
sentencepiece>=0.1.99
pyyaml>=6.0.1
# Optional (Linux CUDA only): flash-attn>=2.5.8
